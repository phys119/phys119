{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2c32fb06-bb63-49c1-aa51-125a423b0747",
   "metadata": {},
   "source": [
    "# Lab 06 notebook tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3318975",
   "metadata": {},
   "source": [
    "<span style=\"color: red;\">**Please do not read through this notebook until after the invention activity in class**</span>\n",
    "\n",
    "A summary of our new tool can be found at the end of this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5b35ac-3c4e-42d4-b63a-46d7c26153a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_entry2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1759948-cdb0-4a74-8d7b-3a78feead5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the prelab data we used for Lab 05\n",
    "de1 = data_entry2.sheet_copy(\"../Lab05/lab05_prelab_hookes_law\", \"lab05prelab-copy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e47a00-266f-48be-98c4-f036fc5cff84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the plots and calculate chi-squared\n",
    "\n",
    "# Scatter step 1: Define the variables we will be plotting, as well as labels and titles\n",
    "# Plotting variables\n",
    "xdata = DxVec\n",
    "ydata = FVec\n",
    "dydata = dFVec\n",
    "\n",
    "# Labels and titles\n",
    "data_label = \"Experimental data\"\n",
    "model_label = \"F = kx\"\n",
    "graph_title = \"Hooke's law investigation using spring compression\"\n",
    "x_label = \"Displacement of spring from equilibrium (m)\"\n",
    "y_label = \"Force (N)\"\n",
    "residuals_title = \"Residuals for Hooke's law investigation using spring compression\"\n",
    "residuals_y_label = \"Residual = data - model (N)\"\n",
    "\n",
    "# Model parameters\n",
    "slope = 2.3 # The initial esimate of the slope\n",
    "# slope = 2.09 # The slope that minimizes chi-squared to 0.57\n",
    "# slope = 2.0 # Lower slope corresponding to chi2 = 0.57 + 1 = approximately 1.57\n",
    "# slope = 2.185 # Higher slope corresponding to chi2 = 0.57 + 1 = approximately 1.57\n",
    "P = 1 # Your number of fitting parameters, to be used in chi-squared calculation.\n",
    "\n",
    "\n",
    "# Scatter step 2: find the limits of the data:\n",
    "xmin = np.min(xdata) # use the np.min function to find the smallest x-value\n",
    "xmax = np.max(xdata) # same for max\n",
    "# print (xmin, xmax)  # uncomment to see what the limits are\n",
    "\n",
    "# Scatter step 3: generate a bunch of x points between xmin and xmax to help us plot the model line\n",
    "xpoints = np.linspace(xmin, xmax, 200) # gives 200 evenly spaced points between xmin and xmax\n",
    "# print(xpoints) # uncomment to see the x values that were generated.\n",
    "\n",
    "# Scatter step 4: calculate the model values:\n",
    "ypoints = xpoints * slope # this calculates the yvalues at all 200 points.\n",
    "\n",
    "# Scatter step 5: plot the model line. We plot this as a red line \"r-\" :\n",
    "plt.plot(xpoints, ypoints, \"r-\", label = model_label)\n",
    "\n",
    "# Scatter step 6: Plot the data, with the previous details from before\n",
    "plt.errorbar(xdata, ydata, dydata, fmt=\"bo\", markersize = 3, label=data_label)\n",
    "plt.title(graph_title)\n",
    "plt.xlabel(x_label)\n",
    "plt.ylabel(y_label)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Residuals step 1: Calculate the model prediction for each our data points from dxVec\n",
    "ymodel = slope * xdata # y = mx\n",
    "\n",
    "# Residuals step 2: Calcualte the residuals vector\n",
    "residualsVec = ydata - ymodel\n",
    "\n",
    "# Residuals step 3: Plot the residuals vector against the x-data vector\n",
    "plt.errorbar(xdata, residualsVec, dydata, fmt=\"bo\", markersize = 3)\n",
    "\n",
    "# Residuals step 4: Add a horizontal line at R=0 to the plot\n",
    "plt.hlines(y=0, xmin=xmin, xmax=xmax, color='k') # draw a black line at y = 0.\n",
    "\n",
    "# Residuals step 5: Add axis labels and title, and show the graph\n",
    "plt.title(residuals_title)\n",
    "plt.xlabel(x_label)\n",
    "plt.ylabel(residuals_y_label)\n",
    "plt.show()\n",
    "\n",
    "# Calculate chi-squared \n",
    "chi2 = np.sum((residualsVec/dydata)**2)/(len(residualsVec)-P)\n",
    "print (\"Slope: \", slope, \"N/m\")\n",
    "print (\"Weighted chi-squared: \", chi2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1c2f60-f771-4772-94d2-6af16c26d0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep track of chi-squared based on changing the slope\n",
    "# - This table is prefilled with example values\n",
    "de_chi2 = data_entry2.sheet('Lab06-demo-table')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e81b32e1-9d7f-4eed-a638-02fea2b9a862",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Best estimate for slope:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f29535a9",
   "metadata": {},
   "source": [
    "* The best estimate of your slope will be the one you find above that has the lowest chi-squared. In this example it is slope = 2.09 N/m, which corresponds to a chi-squared of 0.57\n",
    "* The best estimate of your uncertainties on the slope will be half of the difference between the slightly smaller slope `slope_min` and the slightly larger slope `slope_max` that each increase the chi-squared by approximately +1. Since our minimized chi-squared is 0.57, this means we are looking for the slopes that make chi-squared approximately equal to 1.6. This give `slope_min = 2.0` and `slope_max = 2.185`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cacb11d-3544-49d4-a209-1facf595ab7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best slope\n",
    "slope_best = 2.09 # Gives chi-squared of 0.57\n",
    "slope_max = 2.185 # Give chi-squared of 1.6 (approximately 1 higher than 0.57)\n",
    "slope_min = 2.0 # Gives chi-squared of 1.6 (approximately 1 higher than 0.57)\n",
    "dslope = (slope_max - slope_min)/2.\n",
    "print(\"Slope uncertainty:\", dslope, \"N/m\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6e1c86b1-46d3-4972-a276-3e3da5951cd4",
   "metadata": {},
   "source": [
    "Our best estimate of the slope is 2.090 $\\pm$ 0.093 N/m."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b48c739",
   "metadata": {},
   "source": [
    "# Appendix A: Fitting using reduced chi-squared minimization / weighted least squares fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ab09b2",
   "metadata": {},
   "source": [
    "$$\\large \\chi_w^2 = \\frac{1}{N-P} \\sum_{i=1}^N \\left[ \\frac{y_i - f(x_i) }{\\delta y_i} \\right]^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5da35d",
   "metadata": {},
   "source": [
    "When using chi-squared, the goal is to adjust your fitting parameters in order to minimize the value for chi-squared, which indicates the best possible fit of your model to the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9641b39e",
   "metadata": {},
   "source": [
    "Interpreting $\\large \\chi_w^2$:\n",
    "\n",
    "* $\\large \\chi_w^2 \\approx 1$: The model fits the data well, assuming uncertainties have been characterized well\n",
    "* $\\large \\chi_w^2 \\gg 1$: Not a good fit or the uncertainties have been underestimated\n",
    "* $\\large \\chi_w^2 \\ll 1$: The uncertainties have been overestimated\n",
    "\n",
    "Using chi-squared is a 2-step process:\n",
    "1. First minimize chi-squared by adjusting parameters.\n",
    "2. Then, once it is minimized, interpret the value. \n",
    "\n",
    "The goal is **not** to make chi-squared = 1, it is to minimize it to find the best possible fit, and then interpret the resulting chi-squared value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f40dacc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7bde321-1043-4984-9466-052be7c065d2",
   "metadata": {},
   "source": [
    "# Appendix B: Including a y-intercept in your model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc78df0-6755-473e-a070-6c467084657b",
   "metadata": {},
   "source": [
    "Here we provide an example of how to update everything to include a y-intercept (`intercept`) in your model. This requires the following changes, which are all indicated by `###` in the code below\n",
    "1. In Scatter Step 1, add a y-intercept fitting parameter, `intercept`;\n",
    "2. In Scatter Step 1, update the number of fitting parameters `P` to be 2 since the fitting parameters are `slope` and `intervept`;\n",
    "3. In Scatter Step 4, update the model line to include the y-intercept: `ypoints = slope * xpoints + intercept`;\n",
    "4. In Residuals Step 1, update the model predictions for each data point to include the y-intercept: `ymodel = slope * xdata + intercept`;\n",
    "5. In the final Calculate Chi-squared step, the earlier update of `P` will make the `N-P` term be updated correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650cc7fa-bf49-4327-932c-4addb0fb9c7a",
   "metadata": {},
   "source": [
    "**Note:** This does not actually reduce chi-squared further in this specific example because the additional parameter changes our number of parameters to two, `P=2`. Because the fit is already quite good without this y-intercept, this is telling us that the simpler model is preferred, meaning the `y=mx` model is preferred over the `y=mx+b` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919c5874-3185-4110-8c51-6249a5846199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the plots and calculate chi-squared\n",
    "\n",
    "# Scatter step 1: Define the variables we will be plotting, as well as labels and titles\n",
    "# Plotting variables\n",
    "xdata = DxVec\n",
    "ydata = FVec\n",
    "dydata = dFVec\n",
    "\n",
    "# Labels and titles\n",
    "data_label = \"Experimental data\"\n",
    "model_label = \"F = kx + b\" ### Included a y-intercept\n",
    "graph_title = \"Hooke's law investigation using spring compression\"\n",
    "x_label = \"Displacement of spring from equilibrium (m)\"\n",
    "y_label = \"Force (N)\"\n",
    "residuals_title = \"Residuals for Hooke's law investigation using spring compression\"\n",
    "residuals_y_label = \"Residual = data - model (N)\"\n",
    "\n",
    "# Model parameters\n",
    "slope = 2.09 # The best slope from the y = mx model\n",
    "intercept = 0. ### Added the y-intercept, b\n",
    "P = 2 ### Updated number of fitting parameters to be 2 (m and b)\n",
    "\n",
    "\n",
    "# Scatter step 2: find the limits of the data:\n",
    "xmin = np.min(xdata) # use the np.min function to find the smallest x-value\n",
    "xmax = np.max(xdata) # same for max\n",
    "# print (xmin, xmax)  # uncomment to see what the limits are\n",
    "\n",
    "# Scatter step 3: generate a bunch of x points between xmin and xmax to help us plot the model line\n",
    "xpoints = np.linspace(xmin, xmax, 200) # gives 200 evenly spaced points between xmin and xmax\n",
    "# print(xpoints) # uncomment to see the x values that were generated.\n",
    "\n",
    "# Scatter step 4: calculate the model values:\n",
    "ypoints = slope * xpoints + intercept ### Update the model line to include the y-intercept\n",
    "\n",
    "# Scatter step 5: plot the model line. We plot this as a red line \"r-\" :\n",
    "plt.plot(xpoints, ypoints, \"r-\", label = model_label)\n",
    "\n",
    "# Scatter step 6: Plot the data, with the previous details from before\n",
    "plt.errorbar(xdata, ydata, dydata, fmt=\"bo\", markersize = 3, label=data_label)\n",
    "plt.title(graph_title)\n",
    "plt.xlabel(x_label)\n",
    "plt.ylabel(y_label)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Residuals step 1: Calculate the model prediction for each our data points from dxVec\n",
    "ymodel = slope * xdata + intercept ### Updated model values at the data points to y = mx + b\n",
    "\n",
    "# Residuals step 2: Calcualte the residuals vector\n",
    "residualsVec = ydata - ymodel\n",
    "\n",
    "# Residuals step 3: Plot the residuals vector against the x-data vector\n",
    "plt.errorbar(xdata, residualsVec, dydata, fmt=\"bo\", markersize = 3)\n",
    "\n",
    "# Residuals step 4: Add a horizontal line at R=0 to the plot\n",
    "plt.hlines(y=0, xmin=xmin, xmax=xmax, color='k') # draw a black line at y = 0.\n",
    "\n",
    "# Residuals step 5: Add axis labels and title, and show the graph\n",
    "plt.title(residuals_title)\n",
    "plt.xlabel(x_label)\n",
    "plt.ylabel(residuals_y_label)\n",
    "plt.show()\n",
    "\n",
    "# Calculate chi-squared \n",
    "chi2 = np.sum((residualsVec/dydata)**2)/(len(residualsVec)-P)\n",
    "print (\"Slope: \", slope, \"N/m\")\n",
    "print (\"Weighted chi-squared: \", chi2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffcd35f-6a2c-445c-8db9-aac6c627c78f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
