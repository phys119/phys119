{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d295f05-aa2d-4c6a-9386-e37388c04c42",
   "metadata": {},
   "source": [
    "# Prelab 10: Preparing to reanalyze your Lab 09 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274541f9-025e-43ac-bb5e-34fb6bf97cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import data_entry2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4c40e6-4801-49ca-bcfa-bd26a6fd38fb",
   "metadata": {},
   "source": [
    "In Lab 09, it is likely that you encountered some unexpected behaviour in your data due to background radiation, meaning radiation coming from something other than the source we provided you with, such as cosmic rays. And this background radiation likely posed significant challenges when trying to fit a linear model to `Ln(R)` data. \n",
    "\n",
    "In Lab 10, you will reanlyze your Lab 09 data with a new nonlinear model that accounts for this background radiation. Additionally, you will collect the additional data, mostly at larger thicknesses of shielding, to help you extract the background radiation count-rate parameter from your nonlinear model with a high level of confidence.\n",
    "\n",
    "Unfortunately, we don't have nice analytic solutions that can handle the new nonlinear model we will be using. As a result, we will use a new `fit_plot` widget that works with our linear model to help us find our best-fit parameters through chi-squared minimization. Additionally, in this prelab, we will modify some of our previous fitting and plotting code to see how we can account for this nonlinear model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18350420-765b-4919-a4a1-d39d2eae78b3",
   "metadata": {},
   "source": [
    "## 1. A hypothetical data set that shows a similar type of behaviour to the Lab 09 data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a508a9b-12d3-4b49-a6f8-3a748e9fa6bd",
   "metadata": {},
   "source": [
    "Below we introduce a hypothetical data set that was generated computationally to represent data taken with equipment that will give somewhat different numerical results to those that we would expect to achieve in our lab with our equipment. \n",
    "\n",
    "**The idea is that these data will provide graphs with the same types of shapes that we expect to see with the real lab equipment, but the values we will extract from the nonlinear fits of these hypothetical data WILL NOT MATCH those from the real lab equipment.**\n",
    "\n",
    "In the code cell below, we load and plot the hypothetical data set. Have a look at these plots and then answer the Your Turn question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e6d316-93af-49ce-8285-192e6666a953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run me to load and plot our hypothetical data set\n",
    "\n",
    "# Our data arrays\n",
    "\n",
    "x_h = np.array([\n",
    "        0., 2., 4., 6., 8., 10., 12., 14., 16., 18., 20., 22., 24., 26.\n",
    "        ])  # number sheets of plastic shielding\n",
    "Rate_h = np.array([\n",
    "        18.54237288, 9.06666667, 4.54237288, 2.55, 1.31666667,\n",
    "        0.76666667, 0.48333333, 0.44262295, 0.51666667, 0.35483871,\n",
    "        0.48387097, 0.45070423, 0.68333333, 0.47540984\n",
    "        ])  # counts per second\n",
    "dRate_h = np.array([\n",
    "        0.59006424, 0.38873013, 0.27746959, 0.20615528, 0.14813657,\n",
    "        0.11303883, 0.08975275, 0.08518283, 0.09279607, 0.07565187,\n",
    "        0.08834235, 0.079674, 0.10671874, 0.08828139\n",
    "        ])  # counts per second\n",
    "\n",
    "# Convert rates to log(Rates) for the semi log plot\n",
    "\n",
    "# See Prelab 09 for a reminder of where these equations came from\n",
    "logRate_h = np.log(Rate_h)\n",
    "dlogRate_h = dRate_h / Rate_h\n",
    "\n",
    "# Plot the untransformed data\n",
    "\n",
    "xdata = x_h\n",
    "ydata = Rate_h\n",
    "dydata = dRate_h\n",
    "\n",
    "graph_title = \"Untransformed hypothetical count-rate data\"\n",
    "x_label = \"Shielding Thickness (x, number of plastic sheets)\"\n",
    "y_label = \"Count Rate (R, counts/second)\"\n",
    "\n",
    "plt.figure()\n",
    "plt.errorbar(\n",
    "        xdata, ydata, dydata, marker='.',\n",
    "        linestyle='', label=\"Hypothetical data (Untransformed)\"\n",
    "        )\n",
    "plt.xlabel(x_label)\n",
    "plt.ylabel(y_label)\n",
    "plt.title(graph_title)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot the linearized data\n",
    "\n",
    "xdata = x_h\n",
    "ydata = logRate_h\n",
    "dydata = dlogRate_h\n",
    "\n",
    "graph_title = \"Linearized hypothetical count-rate data (semilog plot)\"\n",
    "x_label = \"Shielding Thickness (x, number of plastic sheets)\"\n",
    "y_label = \"Ln(R)\"\n",
    "\n",
    "plt.figure()\n",
    "plt.errorbar(\n",
    "        xdata, ydata, dydata, marker='.',\n",
    "        linestyle='', label=\"Hypethetical data (Ln transformed)\"\n",
    "        )\n",
    "plt.xlabel(x_label)\n",
    "plt.ylabel(y_label)\n",
    "plt.title(graph_title)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dad13cd-0bd6-4a85-a0b8-9a7610253fca",
   "metadata": {},
   "source": [
    "### Your Turn #1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec49f28b-cb16-4ecd-a244-625252ded4b6",
   "metadata": {},
   "source": [
    "In the top plot (the untransformed hypothetical data) you can see that the count-rate never decays to 0. These counts are coming from background radiation and are not affected by introducing more sheets of our shielding. Similarly, without background radiation, we expect our bottom plot (the semilog plot) to be nice and straight, with $\\mu = -m$, meaning the attentuation coefficient $\\mu$ should be the negative of the slope of this graph. **However,** what we see is that our linearized data start nice and linear but start to plateau around 12 sheets.\n",
    "\n",
    "Based on these graphs, or looking directly at the values in the `Rate_h` vector, what would you estimate the background radiation count-rate to be?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7b413f-5e5c-43e2-beba-42bee46365f3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### **Answer**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab3c08e-a331-4ef7-bfef-42caf880aa7d",
   "metadata": {},
   "source": [
    "The background count-rate appears to be ~ 0.5 counts/second.\n",
    "\n",
    "* You can see this directly in the top plot or the values in the `Rate_h` vector, where the values seem to be scatter around, but near to 0.5 counts/second for shielding thicknesses of 12+.\n",
    "* We can also see in the semilog plot that the data plateau at $\\ln(R) \\approx -0.7$.\n",
    "* Since $\\ln(0.5) \\approx -0.7$, we can see that both graphs lead us to the same conclusion. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846c63ce-3150-4bbe-9568-797b105383fa",
   "metadata": {},
   "source": [
    "## 1.1 Fitting the entire linearized data set\n",
    "\n",
    "Based on the fact that the linearized hypothetical count-rate data do not look linear, we know that it will go poorly if we try to fit a linear $y=mx+b$ model to this data set. But let's perform this fit to demonstrate how poor of a fit it is.\n",
    "\n",
    "Let's grab a copy of our \"2-parameter analytic best-fit solution\" code from Prelab 09 and update the variables, labels and titles, as needed. Below we perform the fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb893559-dec4-42f5-b578-9fd2192cb72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-parameter analytic best-fit solution and plotting from Prelab 09.\n",
    "\n",
    "# Define the variables we will be plotting.\n",
    "xdata = x_h\n",
    "ydata = logRate_h\n",
    "dydata = dlogRate_h\n",
    "\n",
    "# Labels and titles\n",
    "data_label = \"Hypothetical Data (Ln transformed)\"\n",
    "model_label = \"y = mx + b\"\n",
    "graph_title = \"The best-fit line using the two-parameter analytic equations\"\n",
    "x_label = \"Shielding Thickness (x, number of plastic sheets)\"\n",
    "y_label = \"Ln(R)\"\n",
    "residuals_y_label = \"Residual = data - model (units)\"\n",
    "\n",
    "# Find the best 2-parameter model corresponding to the minimized chi-squared.\n",
    "\n",
    "# Calculate Z\n",
    "Z = (\n",
    "    np.sum(1 / dydata**2) * np.sum(xdata**2 / dydata**2)\n",
    "    - np.sum(xdata / dydata**2)**2\n",
    ")\n",
    "\n",
    "# Calculate best fit slope, m\n",
    "m = 1 / Z * (\n",
    "    np.sum(1 / dydata**2) * np.sum(xdata * ydata / dydata**2)\n",
    "    - np.sum(xdata / dydata**2) * np.sum(ydata / dydata**2)\n",
    ")\n",
    "\n",
    "# Calculate best fit y-intercept, b\n",
    "b = 1 / Z * (\n",
    "    np.sum(xdata**2 / dydata**2) * np.sum(ydata / dydata**2)\n",
    "    - np.sum(xdata / dydata**2) * np.sum(xdata * ydata / dydata**2)\n",
    ")\n",
    "\n",
    "# Calculate uncertainty in best fit slope, dm\n",
    "dm = np.sqrt(1 / Z * np.sum(1 / dydata**2))\n",
    "\n",
    "# Calculate uncertainty in best fit y-intercept, db\n",
    "db = np.sqrt(1 / Z * np.sum(xdata**2 / dydata**2))\n",
    "\n",
    "# Print the best fit slope and uncertainty\n",
    "print(\"Best fit slope, m = \", m, \"±\", dm)\n",
    "\n",
    "# Print the best fit y-intercept and uncertainty\n",
    "print(\"Best fit y-intercept, b = \", b, \"±\", db)\n",
    "\n",
    "\n",
    "# Construct the model for plotting and calculating residuals\n",
    "\n",
    "ymodel = m * xdata + b  # best fit model\n",
    "res = ydata - ymodel  # calculate residuals (best fit)\n",
    "wres2 = (res / dydata)**2  # weighted residuals squared\n",
    "\n",
    "\n",
    "# Calculate chi-squared\n",
    "    \n",
    "N = len(xdata)  # number of data points\n",
    "P = 2  # number of parameters in y = mx + b\n",
    "chi2 = np.sum(wres2) / (N - P)  # calculate chi-squared\n",
    "print(f\"chi2 = {chi2:.4f}\")\n",
    "\n",
    "# Plot data and fit\n",
    "\n",
    "plt.figure()\n",
    "plt.errorbar(\n",
    "    xdata, ydata, dydata, marker='.', linestyle='',\n",
    "    color='b', label=data_label\n",
    "    )\n",
    "plt.plot(xdata, ymodel, color='r', label=model_label)\n",
    "plt.xlabel(x_label)\n",
    "plt.ylabel(y_label)\n",
    "plt.title(graph_title)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Plot residuals for the best fit\n",
    "\n",
    "plt.figure()\n",
    "plt.errorbar(xdata, res, dydata, marker='.', linestyle='', color='b')\n",
    "plt.hlines(\n",
    "    y=0, xmin=np.min(xdata), xmax=np.max(xdata), color='k'\n",
    "    )  # draw axis at y = 0\n",
    "plt.xlabel(x_label)\n",
    "plt.ylabel(residuals_y_label)\n",
    "plt.title(f'Residuals plot (best fit, $\\chi^2$={chi2:.4f})')\n",
    "plt.grid()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dbc2d6-ce9f-407f-bb95-dc66a6a3f6e0",
   "metadata": {},
   "source": [
    "### Your Turn #2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fbe612-1234-43af-a98f-1393969857f1",
   "metadata": {},
   "source": [
    "Based on the plots above and the chi-squared value displayed, what are your conclusions about how well the $R(x) = R_0 \\, e^{-\\mu x}$ model fits these data? \n",
    "\n",
    "Keep in mind that for the semilog plot, this model predicts a linear graph of the form $\\text{Ln}(R(x)) = -\\mu x + \\text{Ln}(R_0).$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ee3b21-823c-434a-bb66-8882b00c0e15",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### **Answer**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c745d5d-e4db-4075-b39f-1b704ea89378",
   "metadata": {},
   "source": [
    "We get $\\chi^2=42.4$ and residuals with an extremely obvious trend showing that the linear model does not describe the data very well at all. This is a very poor fit, as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccbff39-221d-487c-a019-d7ac63a2a552",
   "metadata": {},
   "source": [
    "## 1.2 Fitting only the early linear portion of this data set\n",
    "\n",
    "We can see in the scatter and residuals plots above that the data look to be reasonably linear up to and including a shielding thickness of 10 plastic sheets. Without our understanding that there is also a background radiation count-rate in every one of these measurements, our understanding of the situation is that $x > 10$ corresponds to count-rates that are dominated by background radiation. So let's truncate our data set to only include $x \\le 10$ and re-run our fit.\n",
    "\n",
    "Note that we use a special way of subsetting a python array called a mask when defining our variables: `xdata = x_h[x_h<=10]`. This says that our variable `xdata` will be an array that contains only the values from our `x_h` array that are less than or equal to `<= 10`. You do not need to know how to do this, but we point it out here for those curious to learn some new python skills.\n",
    "\n",
    "When we re-run the fit using only those first six data points we get something that looks much more linear based on the scatter and residuals plots, and the fit has a chi-squared value of 0.78. We have a good fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa1b5e5-4e66-4356-825e-5c52f04c9ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-parameter analytic best-fit solution and plotting from Prelab 09\n",
    "\n",
    "# Define the variables we will be plotting\n",
    "xdata = x_h[x_h <= 10]\n",
    "ydata = logRate_h[x_h <= 10]\n",
    "dydata = dlogRate_h[x_h <= 10]\n",
    "\n",
    "# Labels and titles\n",
    "data_label = \"Hypothetical Data\"\n",
    "model_label = \"y = mx + b\"\n",
    "graph_title = \"The best-fit line using the two-parameter analytic equations\"\n",
    "x_label = \"Shielding Thickness (x, number of plastic sheets)\"\n",
    "y_label = \"Ln(R)\"\n",
    "residuals_y_label = \"Residual = data - model (units)\"\n",
    "\n",
    "# Find the best 2-parameter model corresponding to the minimized chi-squared\n",
    "\n",
    "# Calculate Z\n",
    "Z = (\n",
    "    np.sum(1 / dydata**2) * np.sum(xdata**2 / dydata**2)\n",
    "    - np.sum(xdata / dydata**2)**2\n",
    ")\n",
    "\n",
    "# Calculate best fit slope, m\n",
    "m = 1 / Z * (\n",
    "    np.sum(1 / dydata**2) * np.sum(xdata * ydata / dydata**2)\n",
    "    - np.sum(xdata / dydata**2) * np.sum(ydata / dydata**2)\n",
    ")\n",
    "\n",
    "# Calculate best fit y-intercept, b\n",
    "b = 1 / Z * (\n",
    "    np.sum(xdata**2 / dydata**2) * np.sum(ydata / dydata**2)\n",
    "    - np.sum(xdata / dydata**2) * np.sum(xdata * ydata / dydata**2)\n",
    ")\n",
    "\n",
    "# Calculate uncertainty in best fit slope, dm\n",
    "dm = np.sqrt(1 / Z * np.sum(1 / dydata**2))\n",
    "\n",
    "# Calculate uncertainty in best fit y-intercept, db\n",
    "db = np.sqrt(1 / Z * np.sum(xdata**2 / dydata**2))\n",
    "\n",
    "# Print the best fit slope and uncertainty\n",
    "print(\"Best fit slope, m = \", m, \"±\", dm)\n",
    "\n",
    "# Print the best fit y-intercept and uncertainty\n",
    "print(\"Best fit y-intercept, b = \", b, \"±\", db)\n",
    "\n",
    "\n",
    "# Construct the model for plotting and calculating residuals\n",
    "\n",
    "ymodel = m * xdata + b  # best fit model\n",
    "res = ydata - ymodel  # calculate residuals (best fit)\n",
    "wres2 = (res / dydata)**2  # weighted residuals squared\n",
    "\n",
    "\n",
    "# Calculate chi-squared\n",
    "    \n",
    "N = len(xdata)  # number of data points\n",
    "P = 2  # number of parameters in y = mx + b\n",
    "chi2 = np.sum(wres2) / (N - P)  # calculate chi-squared\n",
    "print(f\"chi2 = {chi2:.4f}\")\n",
    "\n",
    "# Plot data and fit\n",
    "\n",
    "plt.figure()\n",
    "plt.errorbar(\n",
    "    xdata, ydata, dydata, marker='.',\n",
    "    linestyle='', color='b', label=data_label\n",
    "    )\n",
    "plt.plot(xdata, ymodel, color='r', label=model_label)\n",
    "plt.xlabel(x_label)\n",
    "plt.ylabel(y_label)\n",
    "plt.title(graph_title)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Plot residuals for the best fit\n",
    "\n",
    "plt.figure()\n",
    "plt.errorbar(xdata, res, dydata, marker='.', linestyle='', color='b')\n",
    "plt.hlines(\n",
    "    y=0, xmin=np.min(xdata), xmax=np.max(xdata), color='k'\n",
    "    )  # draw axis at y = 0.\n",
    "plt.xlabel(x_label)\n",
    "plt.ylabel(residuals_y_label)\n",
    "plt.title(f'Residuals plot (best fit, $\\chi^2$={chi2:.4f})')\n",
    "plt.grid()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca8edb4-8d17-49c0-a412-0382a7cd1b30",
   "metadata": {},
   "source": [
    "### Your Turn #3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205c30f6-2edc-482c-abf2-447b3c463392",
   "metadata": {},
   "source": [
    "Based on the best-fit parameters listed above for our fit on our truncated data set, what value would we report for the attentuation coefficient, $\\mu$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af52544-157f-48f8-af87-7cb1b6d5d33e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### **Answer**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4782ff40-8732-4c41-94a5-e9bda159003d",
   "metadata": {},
   "source": [
    " We would report our attenuation coefficient ($\\mu = -m$) as $\\mu = (0.3307 \\pm 0.0087) \\text{ sheets}^{-1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d016c2f5-fff6-44e7-b144-2947d0bba505",
   "metadata": {},
   "source": [
    "## 2. Introducing the nonlinear model with a background radiation term\n",
    "\n",
    "A quick recap to what we have done so far in this prelab. First, we recognized that background radiation was present in our hypothetical data set (like it was in your Lab 09 data). So we truncated our data so that we only included shielding thicknesses where the radiation from our source dominated our count-rate data. Or to put it another way, we excluded the data where the background was dominiting the count-rates.\n",
    "\n",
    "In Lab 10, we introduce an alternate way to tackle this issue, which is to build the background radiation count-rate directly into our model. To do so, we introduce a new term, $R_b$, the background count-rate, and we write our model as\n",
    "\n",
    "$$R(x) = R_0 \\, e^{-\\mu x} + R_b.$$\n",
    "\n",
    "Like before, $\\mu$ is the attenuation coefficient of the shielding, $x$ is the thickness of the shielding in number of sheets, $R(x)$ is the measured count-rate and $R_0$ is the count-rate with no shielding, as predicted by the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbd5e77-7ac0-4fe6-8040-e96a44de986e",
   "metadata": {},
   "source": [
    "### Your Turn #4\n",
    "\n",
    "Based on our best-fit parameters and other observations of the hypothetical data set from Section 1, we can make reasonable initial estimates for each of the model parameters in \n",
    "\n",
    "$$R(x) = R_0 \\, e^{-\\mu x} + R_b.$$\n",
    "\n",
    "Below we list some reasonable initial estimates for each of these parameters. Try to determine where each of these values comes from and then check the answers to confirm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73969d8-256b-43b2-8f74-c3aafd17abbe",
   "metadata": {},
   "source": [
    "##### **Parameter 1 estimate:** $R_b = 0.5 \\text{ counts/second}.$ \n",
    "How did we estimate this value?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3428a2f-1a0e-4187-8c84-386dfe113a50",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### **Answer**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c486386-a75c-43b9-a828-71f19fb87d5f",
   "metadata": {},
   "source": [
    "This value comes from our earliest observation in this prelab that the data plateau at a count-rate of approximately $0.5$ or $\\ln(-0.7)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afd1b94-dd90-46c2-860a-32942d2c0b9b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### **Parameter 2 estimate:** $R_0 = 18.0 \\text{ counts/second} = (18.5 - 0.5) \\text{ counts/second}.$\n",
    "How did we estimate this value?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221c7a1e-3925-4c36-a75e-444253bc2293",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### **Answer**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3398d6e-70e1-4bb1-9472-56ecdb214bf1",
   "metadata": {},
   "source": [
    "Our count-rate data for shielding thickness = 0 is 18.54237288 counts/second. Given that ~ 0.5 counts/second of this count-rate are due to the background count-rate, that means out no-shielding count-rate from just from the source is ~ 18.5 - 0.5 = 18.0 counts/second."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91f4c03-408b-4675-b51c-cf7a14fa0e30",
   "metadata": {},
   "source": [
    "##### **Parameter 3 estimate:** $\\mu = 0.33 \\text{ sheets}^{-1}$.\n",
    "How did we estimate this value?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c822cc-ac8b-40a4-ae7a-0bc093c09fc3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### **Answer**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e6016f-a903-46c1-ac77-485666233664",
   "metadata": {},
   "source": [
    "The attentuation coefficient can be estimated from the slope of the linear portion of our semilog plot. This is how you determined the attenuation coefficient in Lab 08."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc80dd65-638b-494b-9fec-d58633c49641",
   "metadata": {},
   "source": [
    "## 2.1 Plotting the $R(x) = R_0 \\, e^{-\\mu x} + R_b$ model with the initial guesses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9154b7d9-e193-4dc0-9a22-784e31c9f864",
   "metadata": {},
   "source": [
    "In the previous section we developed some initial guesses for the fitting parameters $R_0$, $\\mu$ and $R_b$. In the figure below we plot the untransformed data and add the line for the $R(x) = R_0 \\, e^{-\\mu x} + R_b$ model using these initial guesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943bbcd5-5318-4206-95ad-5cfc444c2272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial guesses for model parameters\n",
    "\n",
    "R0 = 18  # counts/s\n",
    "mu = 0.33  # 1/sheets\n",
    "Rb = 0.5  # counts/s\n",
    "\n",
    "\n",
    "# Plot the untransformed data\n",
    "\n",
    "xdata = x_h\n",
    "ydata = Rate_h\n",
    "dydata = dRate_h\n",
    "\n",
    "# Find the x and y values for the model line\n",
    "xmin = np.min(xdata)  # use the np.min function to find the smallest x-value\n",
    "xmax = np.max(xdata)  # same for max\n",
    "xpoints = np.linspace(xmin, xmax, 200)\n",
    "ypoints = R0 * np.exp(-mu * xpoints) + Rb  # R0 * e^{-mu*x} + Rb model\n",
    "\n",
    "graph_title = \"Untransformed hypothetical count-rate data\"\n",
    "x_label = \"Shielding Thickness (x, number of plastic sheets)\"\n",
    "y_label = \"Count Rate (R, counts/second)\"\n",
    "\n",
    "plt.figure()\n",
    "plt.errorbar(\n",
    "    xdata, ydata, dydata, marker='.',\n",
    "    linestyle='', label=\"Hypothetical data (Untransformed)\"\n",
    "    )\n",
    "plt.plot(\n",
    "    xpoints, ypoints, \"r-\",\n",
    "    label=\"$R_0 \\, e^{-\\mu x} + R_b$ model using initial guesses\"\n",
    "    )\n",
    "plt.xlabel(x_label)\n",
    "plt.ylabel(y_label)\n",
    "plt.title(graph_title)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94707eba-dd45-470d-80a3-2fcb48517222",
   "metadata": {},
   "source": [
    "We can see in the figure above that, with some adjustments to our initial guesses of the fitting parameters, we could probably have good agreement between our model and data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35d85b0-d941-4c70-95df-cf0d8cd4fa7f",
   "metadata": {},
   "source": [
    "## 2.2 Plotting the $\\text{Ln}(R(x)) = \\text{Ln}(R_0 \\, e^{-\\mu x} + R_b)$ model with the initial guesses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec873313-02dc-4fce-aa83-b87d7ef358e2",
   "metadata": {},
   "source": [
    "Let's now look at how our model with initial guesses looks on our semi-log plot. To do so we use our $\\text{Ln}$ transformed data and our $\\text{Ln}$ transformed model, $\\text{Ln}(R(x)) = \\text{Ln}(R_0 \\, e^{-\\mu x} + R_b)$.\n",
    "\n",
    "The code box below creates a scatter plot, which includes some additional annotations to help relate the fit parameters $R_0$, $\\mu$ and $R_b$ to the shape of the model. Additionally, it creates a residuals plots, outputs the current values of the fit parameters, as well as calculating and outputting chi-squared. It is not expected that you need to be able to follow all of this code. Instead, have a look at the plots that result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0abe2af-3d20-472d-9f54-6db27f985948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the variables we will be plotting, as well as labels and titles\n",
    "\n",
    "# Plotting variables\n",
    "xdata = x_h\n",
    "ydata = logRate_h\n",
    "dydata = dlogRate_h\n",
    "\n",
    "\n",
    "# Construct the model for plotting and calculating residuals\n",
    "\n",
    "# Find the x and y values for the model line\n",
    "xmin = np.min(xdata)  # use the np.min function to find the smallest x-value\n",
    "xmax = np.max(xdata)  # same for max\n",
    "xpoints = np.linspace(xmin, xmax, 200)\n",
    "ypoints = np.log(R0 * np.exp(-mu * xpoints) + Rb)  # R0 * e^{-mu*x} + Rb model\n",
    "\n",
    "# Find the model for the residuals\n",
    "ymodel = np.log(R0 * np.exp(-mu * xdata) + Rb)\n",
    "residualsVec = ydata - ymodel\n",
    "\n",
    "# Create the scatter plot with annotations\n",
    "\n",
    "plt.figure(figsize=(9, 5))\n",
    "\n",
    "# Create the main plots\n",
    "plt.errorbar(\n",
    "    xdata, ydata, dydata, marker='.', \n",
    "    linestyle='', label=\"Hypethetical data (Ln transformed)\"\n",
    "    )\n",
    "plt.plot(\n",
    "    xpoints, ypoints, \"r-\",\n",
    "    label=\"Ln$(R_0 \\, e^{-\\mu x} + R_b)$ model using initial guesses\"\n",
    "    )\n",
    "plt.xlabel(\"Shielding Thickness (x, number of plastic sheets)\")\n",
    "plt.ylabel(\"Ln(R)\")\n",
    "plt.legend(edgecolor='black')  \n",
    "plt.tick_params(axis='both', which='major')\n",
    "plt.grid(color='grey', linestyle='--', alpha=0.6)  # Add slightly darker grid\n",
    "\n",
    "# Rb plateau annotation\n",
    "plt.hlines(\n",
    "    y=np.log(Rb), xmin=xmin - 1.2, xmax=xmax, color='black', linestyle='--'\n",
    "    ) \n",
    "\n",
    "plt.text(\n",
    "    xmin - 6, np.log(Rb), 'Ln(Rb) plateau', \n",
    "    bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.3'),\n",
    "    horizontalalignment='center', verticalalignment='center'\n",
    "    )  # arrow\n",
    "\n",
    "arrow_x = xmin - 1.1  # Adjust this value to position the arrow\n",
    "arrow_y = np.log(Rb)  # Adjust this value to position the arrow\n",
    "plt.annotate(\n",
    "    '', xy=(arrow_x, arrow_y), xytext=(arrow_x - 2., arrow_y),\n",
    "    arrowprops=dict(facecolor='black', shrink=0.15),\n",
    "    horizontalalignment='center', verticalalignment='center'\n",
    "    )  # text box\n",
    "\n",
    "plt.hlines(\n",
    "    y=np.log(R0 + Rb), xmin=xmin - 1.2, xmax=xmin - 0.2,\n",
    "    color='k', linestyle='--'\n",
    "    )  \n",
    "\n",
    "# Ln(R0+Rb) intercept annotation\n",
    "arrow_x = xmin - 1.1  # Adjust this value to position the arrow\n",
    "arrow_y = np.log(R0 + Rb)  # Adjust this value to position the arrow\n",
    "plt.annotate(\n",
    "    '', xy=(arrow_x, arrow_y), xytext=(arrow_x - 2, arrow_y),\n",
    "    arrowprops=dict(facecolor='black', shrink=0.15),\n",
    "    horizontalalignment='center', verticalalignment='center'\n",
    "    )  # arrow\n",
    "plt.text(\n",
    "    xmin - 7.1, np.log(R0 + Rb), 'Ln(R0+Rb) intercept', \n",
    "    bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.3'),\n",
    "    horizontalalignment='center', verticalalignment='center'\n",
    "    )  # text box\n",
    "\n",
    "\n",
    "# mu annotation\n",
    "arrow_x = xmin + 7  # Adjust this value to position the arrow\n",
    "arrow_y = np.log(Rb) + 1.6  # Adjust this value to position the arrow\n",
    "plt.annotate(\n",
    "    '', xy=(arrow_x, arrow_y), xytext=(arrow_x + 1.4, arrow_y + 0.4),\n",
    "    arrowprops=dict(facecolor='black', shrink=0.15),\n",
    "    horizontalalignment='center', verticalalignment='center'\n",
    "    )  # arrow\n",
    "plt.text(\n",
    "    arrow_x + 3.9, arrow_y + 0.6, 'Slope = $-\\mu$',\n",
    "    bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.3'),\n",
    "    horizontalalignment='center', verticalalignment='center'\n",
    "    )  # text box\n",
    "\n",
    "# Set x-axis limit\n",
    "plt.xlim(-10, max(xdata) + 1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Determine residuals, plot residuals and calculate chi-squared\n",
    "\n",
    "ymodel = np.log(R0 * np.exp(-mu * xdata) + Rb)\n",
    "residualsVec = ydata - ymodel\n",
    "\n",
    "plt.figure(figsize=(9, 5))\n",
    "plt.errorbar(\n",
    "    xdata, residualsVec, dydata, fmt=\"o\",\n",
    "    markersize=3, label=\"Residuals\"\n",
    "    )\n",
    "plt.hlines(y=0, xmin=xmin, xmax=xmax, color='k')  # draw a black line at y = 0.\n",
    "plt.xlabel(x_label)  # re-use the x_label from the scatter plot with model\n",
    "plt.ylabel(\"Residual = data - model\")\n",
    "plt.grid(True)\n",
    "plt.xlim(-10, max(xdata) + 1)\n",
    "plt.legend(edgecolor='black')  \n",
    "plt.show()\n",
    "\n",
    "# Calculate chi-squared and output current fit parameter values\n",
    "chi2 = np.sum((residualsVec / dydata)**2) / (len(residualsVec) - 3)\n",
    "print(\"R0: \", R0, \"counts/s\")\n",
    "print(\"mu: \", mu, \"sheets^-1\")\n",
    "print(\"Rb: \", Rb, \"counts/s\")\n",
    "print(\"Ln(R0+Rb): \", np.log(R0 + Rb))\n",
    "print(\"Ln(Rb): \", np.log(Rb))\n",
    "print(\"Weighted chi-squared: \", chi2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdbb5b5-79d2-4a4f-aae6-9661bf592fcb",
   "metadata": {},
   "source": [
    "### Your turn #5\n",
    "\n",
    "Look at the scatter and residuals plots above. Which change to one of the parameters should have the highest impact in improving the fit?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63878f89-392e-490c-acc2-d87088097842",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### **Answer**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f22fdc-082d-4823-acb7-72d70f535555",
   "metadata": {},
   "source": [
    "It looks like the slope parameter (-μ) needs to be steeper, meaning that we need to increase μ. Let's try changing that next."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8b8835-cebc-463e-b91d-1af084764f5b",
   "metadata": {},
   "source": [
    "## 2.3 Adjusting the fit parameters to improve the fit of the $\\text{Ln}(R_0 \\, e^{-\\mu x} + R_b)$ model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203b7a91-a834-4093-995a-96f86858079a",
   "metadata": {},
   "source": [
    "During Lab 10 we will introduce a new `fit_plot` widget to help with the process of minimizing chi-squared. However, for now, we will try increasing our initial guess of $\\mu = 0.33 \\text{ sheets}^{-1}$ to $\\mu = 0.39 \\text{ sheets}^{-1}$ to make the slope of that initial linear portion more steep. Notice that this improves our residuals and our chi-squared goes from 4.3 down to 1.6, so this is certainly an improvement in the model.\n",
    "\n",
    "If you like, try adjusting the three fit parameters further to see if you can get an even better fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0764d437-b27c-4c97-b0b9-040ca135d8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the fit parametes\n",
    "\n",
    "# Left at initial guesses for now\n",
    "R0 = 18  # counts/s\n",
    "Rb = 0.5  # counts/s\n",
    "\n",
    "# Updated from 0.33 to 0.39\n",
    "mu = 0.39  # 1/sheets\n",
    "\n",
    "# Plot the transformed data\n",
    "\n",
    "xdata = x_h\n",
    "ydata = logRate_h\n",
    "dydata = dlogRate_h\n",
    "\n",
    "# Find the x and y values for the model line\n",
    "xmin = np.min(xdata)  # use the np.min function to find the smallest x-value\n",
    "xmax = np.max(xdata)  # same for max\n",
    "xpoints = np.linspace(xmin, xmax, 200)\n",
    "ypoints = np.log(R0 * np.exp(-mu * xpoints) + Rb)  # Ln(R0 * e^{-mu*x} + Rb)\n",
    "\n",
    "graph_title = \"Linearized hypothetical count-rate data (semilog plot)\"\n",
    "x_label = \"Shielding Thickness (x, number of plastic sheets)\"\n",
    "y_label = \"Ln(R)\"\n",
    "\n",
    "plt.figure()\n",
    "plt.errorbar(\n",
    "    xdata, ydata, dydata, marker='.',\n",
    "    linestyle='', label=\"Hypethetical data (Ln transformed)\"\n",
    "    )\n",
    "plt.plot(\n",
    "    xpoints, ypoints, \"r-\",\n",
    "    label=\"Ln$(R_0 \\, e^{-\\mu x} + R_b)$ model using initial guesses\"\n",
    "    )\n",
    "plt.xlabel(x_label)\n",
    "plt.ylabel(y_label)\n",
    "plt.title(graph_title)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Determine residuals and calculate chi-squared\n",
    "\n",
    "ymodel = np.log(R0 * np.exp(-mu * xdata) + Rb)\n",
    "residualsVec = ydata - ymodel\n",
    "\n",
    "plt.figure()\n",
    "plt.errorbar(\n",
    "    xdata, residualsVec, dydata, fmt=\"o\",\n",
    "    markersize=3, label=\"Residuals\"\n",
    "    )\n",
    "plt.hlines(y=0, xmin=xmin, xmax=xmax, color='k')  # draw a black line at y = 0.\n",
    "plt.xlabel(x_label)  # re-use the x_label from the scatter plot with model\n",
    "plt.ylabel(\"Residual = data - model\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Calculate chi-squared and output current fit parameter values\n",
    "chi2 = np.sum((residualsVec / dydata)**2) / (len(residualsVec) - 3)\n",
    "print(\"R0: \", R0, \"counts/s\")\n",
    "print(\"mu: \", mu, \"sheets^-1\")\n",
    "print(\"Rb: \", Rb, \"counts/s\")\n",
    "print(\"Ln(R0+Rb): \", np.log(R0 + Rb))\n",
    "print(\"Ln(Rb): \", np.log(Rb))\n",
    "print(\"Weighted chi-squared: \", chi2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7319908f-cca4-4097-b672-2f9bbc7842fd",
   "metadata": {},
   "source": [
    "## Your turn #6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b77633-11b9-4717-9c81-426979f0c56f",
   "metadata": {},
   "source": [
    "As usual, review the Lab 10 instructions and copy in any analysis code that you feel will be relevant. Some final notes:\n",
    "* Recall that the data set used in this prelab was a hypothetical data set designed to give data with the same general behavour as your Lab 09 data, but where the fitting parameters we used in this prelab will not be the same as what you expect them to be with your Lab 09 data.\n",
    "* You will be expected to add some additional data points to your data set during Lab 10 to help provide your model with better fit parameters.\n",
    "* You will notice in the Lab 10 notebook that we include some code for the new `fit_plot` widget that we will be using to help with fitting the $\\text{Ln}(R_0 \\, e^{-\\mu x} + R_b)$ model to our semilog data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297114ad-bffb-46d3-8493-21395f45674e",
   "metadata": {},
   "source": [
    "# Submit\n",
    "\n",
    "Steps for submission:\n",
    "\n",
    "1. Click: Run => Run_All_Cells\n",
    "2. Read through the notebook to ensure all the cells executed correctly and without error.\n",
    "3. File => Save_and_Export_Notebook_As->HTML\n",
    "4. Inspect your html file\n",
    "5. Upload the HTML document to the lab submission assignment on Canvas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phys119",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
